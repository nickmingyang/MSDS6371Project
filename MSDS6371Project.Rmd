---
title: "MSDS6371Project"
author: "Allen Miller & Mingyang Nick YU"
date: "11/19/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Read in Training Data and initial inspection:
```{r}
#Load required libraries
library(tidyverse)
library(ggplot2)
library(olsrr)
library(GGally)
library(caret)
library(MASS)
library(leaps)
#Load in Dataset
#Call original data amesHouse
amesHouse = read.csv("/Users/mingyang/Desktop/SMU/StatisticalFoundation_Fall2020/MSDS6371Project/train.csv",header = TRUE)
#observe data
head(amesHouse)
str(amesHouse)
#look at neighborhood
amesHouse$Neighborhood
```

#### Analysis 1:
```{r}
#extract variables we're interested for Analysis 1
data1 = amesHouse %>% dplyr::select(SalePrice,GrLivArea,Neighborhood)%>%
  filter(Neighborhood=="NAmes"|Neighborhood=="Edwards"|Neighborhood=="BrkSide")
str(data1)
#383 observations selected after filtering neighborhood of "NAmes", "Edwards" and "BrkSide"
#Convert Neighborhood to factors
data1$Neighborhood = as.factor(data1$Neighborhood)
#Plot and observe the relationship between SalePrice and GrLivArea
data1 %>% ggplot(aes(x=GrLivArea,y=SalePrice))+
  geom_point()+ggtitle("Sale Price vs. Square Foot of Living area")+
  xlab("Square Foot of Living Area")+
  ylab("Sale Price")
#there are some outliers that may not have come from the same population of interest
#build model to identify the outliers
model1 = lm(SalePrice~GrLivArea,data=data1)
summary(model1)
#Look at residual plots and cook's distance
plot(model1)
cooksDistance = data.frame(distance = cooks.distance(model1))
cooksDistance%>%filter(distance>=1)
ols_plot_cooksd_bar(model1)
ols_plot_resid_stand(model1)
#ols_plot_resid_lev(model1)
# Observation 339 has cook's distance larger than 5.6, Observation 131's cook's D is larger than 1 so it may due to the face it is a unique case.
# Observation 169 and 190 has standarlized residual greater than 4, these two observations can also potentially not coming from the same population of interest
# Since our sample is sufficiently large, deleting these four outliers won't make a huge difference.
# Call these new dataset without outliers data2
data2 = data1[-c(131,169,190,339),]
str(data2)
data2 %>% ggplot(aes(x=GrLivArea,y=SalePrice))+
  geom_point()+ggtitle("Sale Price vs. Square Foot of Living area")+
  xlab("Square Foot of Living Area")+
  ylab("Sale Price")
#build new model to double check
model2 = lm(SalePrice~GrLivArea,data=data2)
summary(model2)
plot(model2)
ols_plot_cooksd_bar(model2)
ols_plot_resid_stand(model2)
#Cook's Distance within roughly 0.1, residual within 3, decent amount of observations beyond 2 (within 5%)
#Assumptions met, move on to include categorical variables
model3 = lm(SalePrice~GrLivArea+Neighborhood+GrLivArea*Neighborhood,data=data2)
data2 %>% ggplot(aes(x=GrLivArea,y=SalePrice,color=Neighborhood))+
  geom_point()+ggtitle("Sale Price vs. Square Foot of Living area")+
  xlab("Square Foot of Living Area")+
  ylab("Sale Price")
summary(model3)
plot(model3)
ols_plot_cooksd_bar(model3)
ols_plot_resid_stand(model3)
anova(model3)
confint(model3)
#Assumptions are met, model 3 has higher Adjusted R-squared compared to model2
# Change reference to Edwards to get CI for slope
data2$Neighborhood = relevel(data2$Neighborhood,ref="Edwards")
model3 = lm(SalePrice~GrLivArea+Neighborhood+GrLivArea*Neighborhood,data=data2)
summary(model3)
confint(model3)

# Change reference to NAmes to get CI for slope
data2$Neighborhood = relevel(data2$Neighborhood,ref="NAmes")
model3 = lm(SalePrice~GrLivArea+Neighborhood+GrLivArea*Neighborhood,data=data2)
summary(model3)
confint(model3)


```

#### Analysis 2 - Variable converting & Inspecting relationship:
```{r}
# convert certain columns we need into factor in order to use multi regression model
cols.to.factor = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities",
                   "LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType",
                   "HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st",
                   "Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual",
                   "BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC",
                   "CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType",
                   "GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature",
                   "SaleType","SaleCondition","PoolArea","MoSold","YrSold","Fireplaces","FullBath")
amesHouse[cols.to.factor] = lapply(amesHouse[cols.to.factor],factor)
str(amesHouse)

#Now exploring relationships between continuous variables
amesHouse %>% dplyr::select(SalePrice,LotFrontage,LotArea,YearBuilt,YearRemodAdd,MasVnrArea,BsmtFinSF1,BsmtFinSF2)%>%
  ggpairs()
#Try Logrithmic on SalePrice
amesHouse$lSalePrice = log(amesHouse$SalePrice)
#explore relationship between log SalePrice
amesHouse %>% dplyr::select(lSalePrice,LotFrontage,LotArea,YearBuilt,YearRemodAdd,MasVnrArea,BsmtFinSF1,BsmtFinSF2)%>%
  ggpairs()
#There seem to have a slight improvement between YearBuilt and YearRemodAdd

#Move forward with next batch of exploration
amesHouse %>% dplyr::select(SalePrice,BsmtUnfSF,TotalBsmtSF,X1stFlrSF,X2ndFlrSF,LowQualFinSF,GrLivArea) %>%
  ggpairs()
amesHouse %>% dplyr::select(lSalePrice,BsmtUnfSF,TotalBsmtSF,X1stFlrSF,X2ndFlrSF,LowQualFinSF,GrLivArea) %>%
  ggpairs()
#There seem to have a good linear relationship between lSalePrice and TotalBsmtSF, X1stFlrSF, X2ndFlrSF,GrLivArea
#correlation looks better with lSalePrice comparing to SalePrice

#Move forward with next batch of exploration
amesHouse %>% dplyr::select(SalePrice,BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr,
                     TotRmsAbvGrd)%>%
  ggpairs()
amesHouse %>% dplyr::select(lSalePrice,BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr,
                     TotRmsAbvGrd)%>%
  ggpairs()

#The only variable seem to have good correlation with lSalePrice is FullBath,TotRmsAbvGrd.
#???If we should change BsmtFullBath,BsmtHalfBath,HalfBath,BedroomAbvGr,KitchenAbvGr to factors???
#Keep going
amesHouse %>% dplyr::select(SalePrice,GarageYrBlt,GarageCars,GarageArea) %>% ggpairs()
amesHouse %>% dplyr::select(lSalePrice,GarageYrBlt,GarageCars,GarageArea) %>% ggpairs()
#The above variables all seem to have a good linear correlation with lSalePrice
#Keep going
amesHouse %>% dplyr::select(SalePrice,WoodDeckSF,OpenPorchSF,EnclosedPorch,X3SsnPorch,ScreenPorch,MiscVal)%>%
  ggpairs()
amesHouse %>% dplyr::select(lSalePrice,WoodDeckSF,OpenPorchSF,EnclosedPorch,X3SsnPorch,ScreenPorch,MiscVal)%>%
  ggpairs()
#linear relationships don't seem particularly strong except WoodDeckSF, OpenPorchSF
#Overall, lSalePrice seem to improve the correlation with our important predictors a bit. So we will proceed
#with lSalePrice Analysis

```
### Select key variables that can be used as predictor - based on results above
```{r}
summary(amesHouse)
#LotFrontage has too many missing values, yet it only has 0.356 correlation with lSalePrice, so not using this variable
#Alley has too many missing values, so delete column Alley
#LowQualFinSF has close to no correlaion with lSalePrice, delete
#BsmtHalfBath has close to 0 correlation,delete
#FireplaceQu too much missing data, delete
#X3SsnPorch too little correlation, delete
#PoolQC too much missing data, delete
#MiscFeature too much missing data, delete
#MiscVal too little correlation, delete
#Consder adding: Exterior1nd, Exterior2nd
#Selected variables make sense to predict lSalePrice
amesHouse$PoolYN = ifelse(is.na(amesHouse$PoolQC),"NO","YES")
amesHouse$PoolYN = as.factor(amesHouse$PoolYN)
variables.used = amesHouse %>% 
  dplyr::select(Id,MSSubClass,MSZoning,LotArea,LotConfig,Neighborhood,HouseStyle,
         OverallQual,OverallCond,YearBuilt,YearRemodAdd,MasVnrArea,ExterQual,
         ExterCond,Foundation,BsmtQual,BsmtCond,TotalBsmtSF,
         Heating,CentralAir,X1stFlrSF,GrLivArea,FullBath,KitchenQual,TotRmsAbvGrd,
         Fireplaces,GarageType,GarageCars,PoolYN,MoSold,YrSold,lSalePrice)
str(variables.used)
summary(variables.used)
#Adjusting MasVnrArea
variables.used$MasVnrArea = ifelse(is.na(variables.used$MasVnrArea),0,variables.used$MasVnrArea)
variables.used$BsmtQual = as.character(variables.used$BsmtQual)
variables.used$BsmtQual = ifelse(is.na(variables.used$BsmtQual),"NONE",variables.used$BsmtQual)
variables.used$BsmtQual = as.factor(variables.used$BsmtQual)
#Adjusting BsmtCond
variables.used$BsmtCond = as.character(variables.used$BsmtCond)
variables.used$BsmtCond = ifelse(is.na(variables.used$BsmtCond),"NONE",variables.used$BsmtCond)
variables.used$BsmtCond = as.factor(variables.used$BsmtCond)
#Adjusting GarageType
variables.used$GarageType = as.character(variables.used$GarageType)
variables.used$GarageType = ifelse(is.na(variables.used$GarageType),"NONE",variables.used$GarageType)
variables.used$GarageType = as.factor(variables.used$GarageType)

```


### Stepwise Selection
```{r}
set.seed(11)
train.control <- trainControl(method = "cv", number = 10)
step.model = train(lSalePrice~.-Id, data=variables.used,
                   method="lmStepAIC",
                   trControl = train.control,
                   trace=FALSE)
step.model$results
step.model$finalModel
summary(step.model$finalModel)
print(step.model)
# RMSE = 0.1494448 by 10 fold internal cross-validation
exp(0.1494448)
ols_plot_resid_stand(step.model$finalModel)
ols_plot_cooksd_bar(step.model$finalModel)
```

### Load in Test Data 
```{r}
#Load in test.csv
testData = read.csv("/Users/mingyang/Desktop/SMU/StatisticalFoundation_Fall2020/MSDS6371Project/test.csv",header = TRUE)
#Convert variables we need from N/A to NONE
testData$MasVnrArea = ifelse(is.na(testData$MasVnrArea),0,testData$MasVnrArea)
testData$TotalBsmtSF = ifelse(is.na(testData$TotalBsmtSF),0,testData$TotalBsmtSF)
testData$GarageCars = ifelse(is.na(testData$GarageCars),0,testData$GarageCars)
testData$MSZoning = ifelse(is.na(testData$MSZoning),"RL",testData$MSZoning)
testData$KitchenQual = ifelse(is.na(testData$KitchenQual),"TA",testData$KitchenQual)
testData$MSSubClass = ifelse(testData$MSSubClass==150,180,testData$MSSubClass)
testData$FullBath = ifelse(testData$FullBath==4,3,testData$FullBath)
testData$Fireplaces = ifelse(testData$Fireplaces==4,3,testData$Fireplaces)

testData$BsmtQual = ifelse(is.na(testData$BsmtQual),"NONE",testData$BsmtQual)
testData$BsmtCond = ifelse(is.na(testData$BsmtCond),"NONE",testData$BsmtCond)
testData$GarageType = ifelse(is.na(testData$GarageType),"NONE",testData$GarageType)
#Convert some variables we need into factor
testData[cols.to.factor] = lapply(testData[cols.to.factor],factor)
#create variable PoolYN
testData$PoolYN = ifelse(is.na(testData$PoolQC),"NO","YES")
testData$PoolYN = as.factor(testData$PoolYN)
#select variables needed for testing
testVariable = testData %>% 
  dplyr::select(Id,MSSubClass,MSZoning,LotArea,LotConfig,Neighborhood,HouseStyle,
         OverallQual,OverallCond,YearBuilt,YearRemodAdd,MasVnrArea,ExterQual,
         ExterCond,Foundation,BsmtQual,BsmtCond,TotalBsmtSF,
         Heating,CentralAir,X1stFlrSF,GrLivArea,FullBath,KitchenQual,TotRmsAbvGrd,
         Fireplaces,GarageType,GarageCars,PoolYN,MoSold,YrSold)

```

### run stepwise test and export result to csv file - Kaggle Score 0.15372, CV Press = 0.1494, Adjusted R2 = 0.8975
```{r}
testVariable$lSalePrice = predict(step.model,testVariable)
testVariable$SalePrice = exp(testVariable$lSalePrice)
result.stepwise = testVariable %>% dplyr::select(Id,SalePrice)
write.csv(result.stepwise,"stepwise_Prediction_Miller_YU.csv",row.names = FALSE)
```

### Forward Selection - Kaggle Score 0.15432, CV Press estimate = 0.14199, Adjusted R2 = 0.89575
```{r}
set.seed(116)
#create forward fit model

#write a program to generate 5 different combination to Cross-Validate Forward Selection Model
iterations = 5
splitPerc = 0.9
total_RMSE = 0
for(i in 1:iterations){
  print(i)
  trainIndices = sample(1:dim(variables.used)[1],round(splitPerc * dim(variables.used)[1]))
  train = variables.used[trainIndices,]
  test = variables.used[-trainIndices,]
  forward_fit = lm(lSalePrice~.-Id,data=train)
  forward.model = ols_step_forward_aic(forward_fit,penter=0.15)
  prediction = predict(forward.model$model,test)
  squared_MSPE = mean((test$lSalePrice - prediction)^2)
  temp_RMSE = sqrt(squared_MSPE)
  total_RMSE = total_RMSE+temp_RMSE
}
#total RMSE = 0.1235978... 
total_RMSE/iterations

#Build model with full dataset for fitting
forward_fit = lm(lSalePrice~.-Id,data=variables.used)
forward.model = ols_step_forward_aic(forward_fit,penter=0.15)
forward.model$model
forward.model
ols_plot_resid_stand(forward.model$model)
ols_plot_cooksd_bar(forward.model$model)
plot(forward.model$model)

testVariable$lSalePriceForward = predict(forward.model$model,testVariable)
testVariable$SalePrice = exp(testVariable$lSalePriceForward)
result.forward = testVariable %>% dplyr::select(Id,SalePrice)
write.csv(result.forward,"Forward_Prediction_Miller_YU_2.csv",row.names = FALSE)

#Try Mass Library Forward model
forward.model2 = stepAIC(forward_fit,direction="forward")
forward.model2$model

```

### Backward Selection - Kaggle Score 0.15432, CV-Press = 0.148, adjusted R2 = 0.89575
```{r}
set.seed(112)
#create forward fit model

#write a program to pretict 5 different combination to test forward selection model
iterations = 5
splitPerc = 0.95
total_RMSE = 0
for(i in 1:iterations){
  print(i)
  trainIndices = sample(1:dim(variables.used)[1],round(splitPerc * dim(variables.used)[1]))
  train = variables.used[trainIndices,]
  test = variables.used[-trainIndices,]
  backward_fit = lm(lSalePrice~.-Id,data=train)
  backward.model = ols_step_backward_aic(backward_fit)
  prediction = predict(backward.model$model,test)
  squared_MSPE = mean((test$lSalePrice - prediction)^2)
  temp_RMSE = sqrt(squared_MSPE)
  total_RMSE = total_RMSE+temp_RMSE
}
#CV Press Estimate = 0.1481379
total_RMSE/iterations

#Build model with full dataset for fitting
backward_fit = lm(lSalePrice~.-Id,data=variables.used)
backward.model = ols_step_backward_aic(backward_fit)
backward.model$model
backward.model
ols_plot_resid_stand(backward.model$model)
ols_plot_cooksd_bar(backward.model$model)
plot(backward.model$model)

testVariable$lSalePriceBackward = predict(backward.model$model,testVariable)
testVariable$SalePrice = exp(testVariable$lSalePriceBackward)
result.backward = testVariable %>% dplyr::select(Id,SalePrice)
write.csv(result.backward,"Backward_Prediction_Miller_YU.csv",row.names = FALSE)


#Try Mass Library Forward model - Same result 0.15432
backward.model2 = stepAIC(backward_fit,direction="backward")
backward.model2

#Testing with Mass Library
testVariable$lSalePriceBackward = predict(backward.model2,testVariable)
testVariable$SalePrice = exp(testVariable$lSalePriceBackward)
result.backward = testVariable %>% dplyr::select(Id,SalePrice)
write.csv(result.backward,"Backward_Prediction_2_Miller_YU.csv",row.names = FALSE)
```

### Backward Selection - use p-value - Kaggle 0.15505
```{r}
set.seed(16)
#create forward fit model

#write a program to pretict 20 different combination to test forward selection model
iterations = 20
splitPerc = 0.95
total_RMSE = 0
for(i in 1:iterations){
  print(i)
  trainIndices = sample(1:dim(variables.used)[1],round(splitPerc * dim(variables.used)[1]))
  train = variables.used[trainIndices,]
  test = variables.used[-trainIndices,]
  backward_fit = lm(lSalePrice~.-Id,data=train)
  backward.model = ols_step_backward_p(backward_fit,prem=0.1,details=FALSE)
  prediction = predict(backward.model$model,test)
  squared_MSPE = mean((test$lSalePrice - prediction)^2)
  temp_RMSE = sqrt(squared_MSPE)
  total_RMSE = total_RMSE+temp_RMSE
}
#CV Press estimate = 0.1306067
total_RMSE/iterations
#Build model with full dataset for fitting
backward_fit = lm(lSalePrice~.-Id,data=variables.used)
backward.model = ols_step_backward_p(backward_fit,prem=0.1,details=FALSE)
backward.model$model
backward.model
ols_plot_resid_stand(backward.model$model)
ols_plot_cooksd_bar(backward.model$model)
plot(backward.model$model)

testVariable$lSalePriceBackward = predict(backward.model$model,testVariable)
testVariable$SalePrice = exp(testVariable$lSalePriceBackward)
result.backward = testVariable %>% dplyr::select(Id,SalePrice)
write.csv(result.backward,"Backward_Prediction_usingP_Miller_YU.csv",row.names = FALSE)
```

### Custom Model - Kaggle Score = 0.14773, CV-Press = 0.1649, Adjusted R2 = 0.9207
```{r}
#reload data
amesHouse = read.csv("/Users/mingyang/Desktop/SMU/StatisticalFoundation_Fall2020/MSDS6371Project/train.csv",header = TRUE)
summary(amesHouse)
library(mice) #Load mice library to analyze the pattern of missing data
md.pattern(amesHouse)
#imputing missing data using predictive mean matching
tempData <- mice(amesHouse,m=1,maxit=50,meth='pmm',seed=20)
amesHouse = complete(tempData,1)
summary(amesHouse)



#Convert certain variables into factors
cols.to.factor = c("MSSubClass","MSZoning","Street","Alley","LotShape","LandContour","Utilities",
                   "LotConfig","LandSlope","Neighborhood","Condition1","Condition2","BldgType",
                   "HouseStyle","OverallQual","OverallCond","RoofStyle","RoofMatl","Exterior1st",
                   "Exterior2nd","MasVnrType","ExterQual","ExterCond","Foundation","BsmtQual",
                   "BsmtCond","BsmtExposure","BsmtFinType1","BsmtFinType2","Heating","HeatingQC",
                   "CentralAir","Electrical","KitchenQual","Functional","FireplaceQu","GarageType",
                   "GarageFinish","GarageQual","GarageCond","PavedDrive","PoolQC","Fence","MiscFeature",
                   "SaleType","SaleCondition","PoolArea","MoSold","YrSold","Fireplaces","FullBath")
amesHouse[cols.to.factor] = lapply(amesHouse[cols.to.factor],factor)


amesHouse$PoolYN = ifelse(is.na(amesHouse$PoolQC),"NO","YES")
amesHouse$PoolYN = as.factor(amesHouse$PoolYN)
#First test with first few variables
models1 = regsubsets(SalePrice~MSSubClass+MSZoning+LotFrontage+LotArea+Street+Alley+LotShape, data = amesHouse, nvmax = 10)
summary(models1)
#Choose the optimal model
res.sum <- summary(models1)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# As we can see among the variables selected MSSubClass, MSZoning,LotArea,Alley has variables that are significant

#Next set of variables
models2 = regsubsets(SalePrice~LandContour+Utilities+LotConfig+LandSlope+Neighborhood+Condition1+Condition2, data = amesHouse, nvmax = 15)
summary(models2)
#Choose the optimal model
res.sum <- summary(models2)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# LotConfig, Neighborhood, Condition2 has most variables that can be significant

#Next set of variables
models3 = regsubsets(SalePrice~BldgType+HouseStyle+OverallQual+OverallCond+YearBuilt, data = amesHouse, nvmax = 10)
summary(models3)
#Choose the optimal model
res.sum <- summary(models3)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# BldgType, Neighborhood, OverallQual, YearBuilt has most variables that can be significant

#Next set of variables
models4 = regsubsets(SalePrice~YearRemodAdd+RoofStyle+RoofMatl+Exterior1st+Exterior2nd, data = amesHouse, nvmax = 10)
summary(models4)
#Choose the optimal model
res.sum <- summary(models4)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# YearRemodAdd, RoofStyleHip, RoofMatl, Exterior1st, Exterior2nd has most variables that can be significant

#Next set of variables
models5 = regsubsets(SalePrice~MasVnrType+MasVnrArea+ExterQual+ExterCond+Foundation, data = amesHouse, nvmax = 10)
summary(models5)
#Choose the optimal model
res.sum <- summary(models5)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# MasVnrType, MasVnrArea, ExterQual, Foundation, have most variables that can be significant

#Next set of variables all basement section
models6 = regsubsets(SalePrice~BsmtQual+BsmtCond+BsmtExposure+BsmtFinType1+BsmtFinSF1+
                       BsmtFinType2+BsmtFinSF2+BsmtUnfSF+TotalBsmtSF, data = amesHouse, nvmax = 15)
summary(models6)
#Choose the optimal model
res.sum <- summary(models6)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# BsmtQual, BsmtFinType1, TotalBsmtSF have most variables that can be significant

#Next set of variables  - Utilities
models7 = regsubsets(SalePrice~Heating+HeatingQC+CentralAir+Electrical, data = amesHouse, nvmax = 10)
summary(models7)
#Choose the optimal model
res.sum <- summary(models7)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# Heating, HeatingQC, CentralAir,Elecrical have most variables that can be significant

#Next set of variables  - Square foots
models8 = regsubsets(SalePrice~X1stFlrSF+X2ndFlrSF+LowQualFinSF+GrLivArea+BsmtFullBath+BsmtHalfBath+FullBath+HalfBath, data = amesHouse, nvmax = 10)
summary(models8)
#Choose the optimal model
res.sum <- summary(models8)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# X1stFlrSF, X2ndFlrSF, LowQualFinSF,GrLivArea,BsmtFullBath,BsmtHalfBath,FullBath1,HalfBath have most variables that can be significant

#Next set of variables  - Square foots
models9 = regsubsets(SalePrice~BedroomAbvGr+KitchenAbvGr+KitchenQual+TotRmsAbvGrd+Functional, data = amesHouse, nvmax = 10)
summary(models9)
#Choose the optimal model
res.sum <- summary(models9)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# BedroomAbvGr, KitchenAbvGr, KitchenQual,TotRmsAbvGrd have most variables that can be significant

#Next set of variables  
models10 = regsubsets(SalePrice~Fireplaces+FireplaceQu+GarageType+GarageYrBlt+
                        GarageFinish+GarageCars+GarageArea+GarageQual+GarageCond, data = amesHouse, nvmax = 10)
summary(models10)
#Choose the optimal model
res.sum <- summary(models10)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# Fireplaces, FireplaceQu, GarageFinish,GarageCars,GarageArea have most variables that can be significant

#Next set of variables  
models11 = regsubsets(SalePrice~PavedDrive+WoodDeckSF+OpenPorchSF+EnclosedPorch+
                        X3SsnPorch+ScreenPorch, data = amesHouse, nvmax = 10)
summary(models11)
#Choose the optimal model
res.sum <- summary(models11)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# PavedDriveY, WoodDeckSF, OpenPorchSF,X3SsnPorch,ScreenPorch have most variables that can be significant

#Next set of variables  
models12 = regsubsets(SalePrice~PoolYN+Fence+MiscVal+MoSold+YrSold, data = amesHouse, nvmax = 10)
summary(models12)
#Choose the optimal model
res.sum <- summary(models12)
data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)
# PoolYN, Fence, MoSold,YrSold have most variables that can be significant

#Select Variables
custom.var = amesHouse %>% 
  dplyr::select(Id,MSSubClass, MSZoning,LotArea,LotConfig, Neighborhood, Condition2,
                BldgType, Neighborhood, OverallQual, YearBuilt,YearRemodAdd, RoofStyle, RoofMatl, Exterior1st, Exterior2nd,
                MasVnrType, MasVnrArea, ExterQual, Foundation, BsmtQual, BsmtFinType1, TotalBsmtSF,
                Heating, HeatingQC, CentralAir,Electrical,
                X1stFlrSF, X2ndFlrSF, LowQualFinSF,GrLivArea,BsmtFullBath,BsmtHalfBath,FullBath,HalfBath,
                BedroomAbvGr, KitchenAbvGr, KitchenQual,TotRmsAbvGrd,
                Fireplaces,GarageCars,GarageArea,
                PavedDrive, WoodDeckSF, OpenPorchSF,X3SsnPorch,ScreenPorch,
                PoolYN, MoSold,YrSold,
                SalePrice)
custom.var$SalePrice = log(custom.var$SalePrice)
custom.var$GrLivArea = log(custom.var$GrLivArea)

#Adjusting NA factors
custom.var$MasVnrType = as.character(custom.var$MasVnrType)
custom.var$MasVnrType = ifelse(is.na(custom.var$MasVnrType),"NONE",custom.var$MasVnrType)
custom.var$MasVnrType = as.factor(custom.var$MasVnrType)

custom.var$BsmtQual = as.character(custom.var$BsmtQual)
custom.var$BsmtQual = ifelse(is.na(custom.var$BsmtQual),"NONE",custom.var$BsmtQual)
custom.var$BsmtQual = as.factor(custom.var$BsmtQual)

custom.var$BsmtFinType1 = as.character(custom.var$BsmtFinType1)
custom.var$BsmtFinType1 = ifelse(is.na(custom.var$BsmtFinType1),"Unf",custom.var$BsmtFinType1)
custom.var$BsmtFinType1 = as.factor(custom.var$BsmtFinType1)

custom.var$Electrical = as.character(custom.var$Electrical)
custom.var$Electrical = ifelse(is.na(custom.var$Electrical),"SBrkr",custom.var$Electrical)
custom.var$Electrical = as.factor(custom.var$Electrical)

#Model Training
set.seed(11)
train.control <- trainControl(method = "cv", number = 10)
custom.model = train(SalePrice~.-Id, data=custom.var,
                   method="lmStepAIC",
                   trControl = train.control,
                   trace=FALSE)
custom.model$results
custom.model$finalModel
summary(custom.model$finalModel)
print(custom.model)
# RMSE = 0.1494448 by 10 fold internal cross-validation

ols_plot_resid_stand(custom.model$finalModel)
ols_plot_cooksd_bar(custom.model$finalModel)
plot(custom.model$finalModel)
#Load in testing data and fill in the missing data in the same manner
testData = read.csv("/Users/mingyang/Desktop/SMU/StatisticalFoundation_Fall2020/MSDS6371Project/test.csv",header = TRUE)
testData$MSSubClass = ifelse(testData$MSSubClass==150,180,testData$MSSubClass)
testData$FullBath = ifelse(testData$FullBath==4,3,testData$FullBath)
testData$Fireplaces = ifelse(testData$Fireplaces==4,3,testData$Fireplaces)
testData$MasVnrArea = ifelse(is.na(testData$MasVnrArea),0,testData$MasVnrArea)
testData$TotalBsmtSF = ifelse(is.na(testData$TotalBsmtSF),0,testData$TotalBsmtSF)
testData$BsmtFullBath = ifelse(is.na(testData$BsmtFullBath),0,testData$BsmtFullBath)
testData$BsmtHalfBath = ifelse(is.na(testData$BsmtHalfBath),0,testData$BsmtHalfBath)
testData$GarageCars = ifelse(is.na(testData$GarageCars),0,testData$GarageCars)
testData$GarageArea = ifelse(is.na(testData$GarageArea),0,testData$GarageArea)
testData[cols.to.factor] = lapply(testData[cols.to.factor],factor)

testData$PoolYN = ifelse(is.na(testData$PoolQC),"NO","YES")
testData$PoolYN = as.factor(testData$PoolYN)
summary(testData)
#Testing test set
testData1 = testData %>% 
  dplyr::select(Id,MSSubClass, MSZoning,LotArea,LotConfig, Neighborhood, Condition2,
                BldgType, Neighborhood, OverallQual, YearBuilt,YearRemodAdd, RoofStyle, RoofMatl, Exterior1st, Exterior2nd,
                MasVnrType, MasVnrArea, ExterQual, Foundation, BsmtQual, BsmtFinType1, TotalBsmtSF,
                Heating, HeatingQC, CentralAir,Electrical,
                X1stFlrSF, X2ndFlrSF, LowQualFinSF,GrLivArea,BsmtFullBath,BsmtHalfBath,FullBath,HalfBath,
                BedroomAbvGr, KitchenAbvGr, KitchenQual,TotRmsAbvGrd,
                Fireplaces,GarageCars,GarageArea,
                PavedDrive, WoodDeckSF, OpenPorchSF,X3SsnPorch,ScreenPorch,
                PoolYN, MoSold,YrSold)
testData1$GrLivArea = log(testData1$GrLivArea)
summary(testData1)
#Adjusting NA factors
testData1$MSZoning = as.character(testData1$MSZoning)
testData1$MSZoning = ifelse(is.na(testData1$MSZoning),"RL",testData1$MSZoning)
testData1$MSZoning = as.factor(testData1$MSZoning)

testData1$Exterior1st = as.character(testData1$Exterior1st)
testData1$Exterior1st = ifelse(is.na(testData1$Exterior1st),"Other",testData1$Exterior1st)
testData1$Exterior1st = as.factor(testData1$Exterior1st)

testData1$Exterior2nd = as.character(testData1$Exterior2nd)
testData1$Exterior2nd = ifelse(is.na(testData1$Exterior2nd),"Other",testData1$Exterior2nd)
testData1$Exterior2nd = as.factor(testData1$Exterior2nd)

testData1$BsmtQual = as.character(testData1$BsmtQual)
testData1$BsmtQual = ifelse(is.na(testData1$BsmtQual),"TA",testData1$BsmtQual)
testData1$BsmtQual = as.factor(testData1$BsmtQual)

testData1$BsmtFinType1 = as.character(testData1$BsmtFinType1)
testData1$BsmtFinType1 = ifelse(is.na(testData1$BsmtFinType1),"Unf",testData1$BsmtFinType1)
testData1$BsmtFinType1 = as.factor(testData1$BsmtFinType1)

testData1$KitchenQual = as.character(testData1$KitchenQual)
testData1$KitchenQual = ifelse(is.na(testData1$KitchenQual),"TA",testData1$KitchenQual)
testData1$KitchenQual = as.factor(testData1$KitchenQual)

testData1$MasVnrType = as.character(testData1$MasVnrType)
testData1$MasVnrType = ifelse(is.na(testData1$MasVnrType),"None",testData1$MasVnrType)
testData1$MasVnrType = as.factor(testData1$MasVnrType)

testData1$Exterior1st = as.character(testData1$Exterior1st)
testData1$Exterior1st = ifelse(testData1$Exterior1st=="Other","VinylSd",testData1$Exterior1st)
testData1$Exterior1st = as.factor(testData1$Exterior1st)

testData1$SalePrice = predict(custom.model,testData1)
testData1$SalePrice = exp(testData1$SalePrice)
custom.result = testData1 %>% dplyr::select(Id,SalePrice)
write.csv(custom.result,"custom_model_Miller_YU.csv",row.names = FALSE)
```

















